#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script para finalizar 100% da tradu√ß√£o do manuscrito
Identifica e traduz todos os trechos remanescentes em portugu√™s
"""

import re

# Dicion√°rio de tradu√ß√µes para os trechos remanescentes identificados
traducoes = {
    # Se√ß√£o 3.2 - Robustez espacial
    r"Regarding √† robustez espacial, apenas 23% dos estudos aplicaram valida√ß√£o independente geograficamente, registrando-se decr√©scimos de accuracy entre 2% e 15% quando os modelos s√£o expostos a novos conjuntos de dados \[@Effrosynidis2021\]\. Esses resultados corroboratesm a hip√≥tese de sobreajuste \(\*overfitting\*\) a contextos locais, conforme discutido por \\@Kuhn2013\. Additionally, a baixa taxa de implementa√ß√£o de m√©tricas de explicabilidade \(XAI\), presentes em 14% das pesquisas, dificulta a adequa√ß√£o aos requisitos de auditabilidade regulat√≥ria, uma vez que modelos do tipo \"caixa-preta\" n√£o oferecem a traceability decis√≥ria exigida por √≥rg√£os de certifica√ß√£o \[@Lundberg2017\]\.":
    r"Regarding spatial robustness, only 23% of studies applied geographically independent validation, registering accuracy decreases between 2% and 15% when models are exposed to new datasets [@Effrosynidis2021]. These results corroborate the overfitting hypothesis to local contexts, as discussed by @Kuhn2013. Additionally, the low implementation rate of explainability metrics (XAI), present in 14% of research, hinders adequacy to regulatory auditability requirements, since \"black-box\" models do not offer the decision traceability required by certification bodies [@Lundberg2017].",
    
    # Se√ß√£o 3.2 - Detec√ß√£o de fraudes
    r"J√° para a detec√ß√£o de fraudes, prevalecem abordagens de classifica√ß√£o bin√°ria via SVM e KNN para matrizes como mel e azeite\. A modelagem dicot√¥mica \(aut√™ntico \*versus\* fraudulento\) tende a n√£o contabilizar gradientes de adultera√ß√£o ou zonas de transi√ß√£o biogeogr√°fica\. Tolelamente, a integra√ß√£o de \*Blockchain\* e \*Machine Learning\*, observada em 21% dos estudos de traceability, enfrenta desafios de valida√ß√£o na entrada de dados\. Although o registro distribu√≠do assegure a imutabilidade da informa√ß√£o, a veracidade da correspond√™ncia f√≠sico-digital depende da precis√£o dos \"or√°culos\" \(sensores ou modelos preditivos\), cuja interoperabilidade t√©cnica ainda √© incipiente \[@Wang2025\]\.":
    r"For fraud detection, binary classification approaches via SVM and KNN prevail for matrices such as honey and oil. Dichotomous modeling (authentic *versus* fraudulent) tends not to account for adulteration gradients or biogeographical transition zones. Totally, the integration of *Blockchain* and *Machine Learning*, observed in 21% of traceability studies, faces data entry validation challenges. Although distributed registry ensures information immutability, the veracity of physical-digital correspondence depends on the precision of \"oracles\" (sensors or predictive models), whose technical interoperability is still incipient [@Wang2025].",
    
    # Se√ß√£o 3.2 - Network analysis
    r"Network analysis confirms the formation of distinct methodological clusters \(modularidade \$Q = 0,62\$\), com alta densidade interna \(0,53‚Äì0,68\)\.":
    r"Network analysis confirms the formation of distinct methodological clusters (modularity $Q = 0.62$), with high internal density (0.53‚Äì0.68).",
    
    # Se√ß√£o 3.3 - Legenda Figura 3
    r"\*\*Figure 3\.\*\* Temporal evolution de \(a\) produtos com Indica√ß√£o Geogr√°fica \(IG\) registrados por categoria e \(b\) ado√ß√£o dos principais algoritmos de Machine Learning em estudos de IG\.":
    r"**Figure 3.** Temporal evolution of (a) products with Geographical Indication (GI) registered by category and (b) adoption of main Machine Learning algorithms in GI studies.",
    
    # Se√ß√£o 3.4 - Compartimentaliza√ß√£o
    r"This methodological compartmentalization does not represents merely technical preferences, but reflects the sedimentation of regional laboratory practices over decades, consolidated through publica√ß√µes, transfer√™ncia de conhecimento entre grupos de pesquisa e padroniza√ß√£o de protocolos em ag√™ncias regulat√≥rias \[@Spyros2023FoodAuth, @Agiomyrgiannaki2023\]\.":
    r"This methodological compartmentalization does not represent merely technical preferences, but reflects the sedimentation of regional laboratory practices over decades, consolidated through publications, knowledge transfer among research groups, and protocol standardization in regulatory agencies [@Spyros2023FoodAuth, @Agiomyrgiannaki2023].",
    
    # Se√ß√£o 3.4 - Trade-off metrol√≥gico
    r"However, demands for portable devices \(\*field-deployable\*\) imp√µe um \*trade-off\* metrol√≥gico que tensiona os requisitos do Digital Terroir: a necess√°ria compress√£o de modelos para opera√ß√£o \*in situ\* resulta em uma perda de accuracy de 10‚Äì15% em compara√ß√£o aos padr√µes laboratoriais \[@Meena2024; @Effrosynidis2021\]\. Such discrepancy evidences current tension between field tool accessibility and robustness required for official certification, signaling that transitioning to operational Digital Twins demands not only avan√ßos algor√≠tmicos, mas tamb√©m inova√ß√£o em hardware anal√≠tico port√°til que preserve a precis√£o metrol√≥gica\.":
    r"However, demands for portable devices (*field-deployable*) impose a metrological *trade-off* that tensions Digital Terroir requirements: the necessary model compression for *in situ* operation results in an accuracy loss of 10‚Äì15% compared to laboratory standards [@Meena2024; @Effrosynidis2021]. Such discrepancy evidences current tension between field tool accessibility and robustness required for official certification, signaling that transitioning to operational Digital Twins demands not only algorithmic advances, but also innovation in portable analytical hardware preserving metrological precision.",
    
    # Se√ß√£o 3.5 - Figura 4 legenda
    r"\*\*Figure 4\.\*\* Impact of spatial validation na performance degradation em testes externos\.":
    r"**Figure 4.** Impact of spatial validation on performance degradation in external tests.",
    
    r"\*Note: Modelos sem spatial validation present 110% higher accuracy drop when applied to geographically independent regions \(\*\$p < 0,001\$, \$d = 0,948\$\)\. The dashed line indicates the acceptable degradation threshold \(‚â§8%\) proposed for Digital Terroir certification systems\. \$n = 148\$ estudos\.":
    r"*Note: Models without spatial validation present 110% higher accuracy drop when applied to geographically independent regions (*$p < 0.001$, $d = 0.948$). The dashed line indicates the acceptable degradation threshold (‚â§8%) proposed for Digital Terroir certification systems. $n = 148$ studies.",
    
    # Se√ß√£o 3.5 - Transpar√™ncia e XAI
    r"Regarding √† transpar√™ncia, apenas 13,5% dos trabalhos adotaram t√©cnicas of Explainable Artificial Intelligence \(XAI\)\. Observou-se uma correla√ß√£o negativa moderada entre explicabilidade e accuracy \(\$\\rho = -0,481, p < 0,001\$\), contudo, a penalidade absoluta de desempenho foi marginal \(1,53 pontos percentuais, n√£o significativa\)\. Em contrapartida, o custo computacional aumentou substancialmente \(\+67,8% em tempo de processamento\)\. A an√°lise de Pareto identificou o algoritmo XGBoost como o ponto √≥timo de equil√≠brio entre auditabilidade, accuracy e custo, superando arquiteturas de Deep Learning para fins regulat√≥rios \(Figura 5\)\.":
    r"Regarding transparency, only 13.5% of works adopted Explainable Artificial Intelligence (XAI) techniques. A moderate negative correlation was observed between explainability and accuracy ($\\rho = -0.481, p < 0.001$), however, the absolute performance penalty was marginal (1.53 percentage points, not significant). In contrast, computational cost increased substantially (+67.8% in processing time). Pareto analysis identified the XGBoost algorithm as the optimal balance point among auditability, accuracy, and cost, surpassing Deep Learning architectures for regulatory purposes (Figure 5).",
    
    # Se√ß√£o 3.5 - Figura 5
    r"\*\*Figure 5\.\*\* Trade-off between explainability algor√≠tmica e desempenho preditivo\.":
    r"**Figure 5.** Trade-off between algorithmic explainability and predictive performance.",
    
    r"\*Note: Algoritmos mais explic√°veis apresentam correla√ß√£o negativa moderada com accuracy \(\*\$\\rho = -0,481\$, \$p < 0,001\$\), mas o custo absoluto √© modesto \(\\~1,5 pontos percentuais\)\. XGBoost destaca-se como algoritmo com melhor balan√ßo multi-crit√©rio \(score de Pareto = 0,650, considerando accuracy 93%, explicabilidade 6/10 e tempo 12 min\)\. \$n = 148\$ estudos\.":
    r"*Note: More explainable algorithms present moderate negative correlation with accuracy (*$\\rho = -0.481$, $p < 0.001$), but absolute cost is modest (~1.5 percentage points). XGBoost stands out as algorithm with best multi-criteria balance (Pareto score = 0.650, considering 93% accuracy, 6/10 explainability, and 12 min time). $n = 148$ studies.",
    
    # Se√ß√£o 3.5 - Meta-an√°lise
    r"Meta-analysis de 129 estudos indicou uma accuracy global \(pooled\) de 90,66% \[IC 95%: 89,8‚Äì91,4%\]\. O algoritmo PLS-DA obteve o melhor desempenho m√©dio \(92,95%\), seguido por Random Forest \(91,33%\)\. Entretanto, o teste de Egger detectou publication bias severo \(\$z = 40,02, p < 0,001\$\)\. A corre√ß√£o pelo m√©todo trim-and-fill \(imputa√ß√£o de 42 estudos te√≥ricos faltantes\) reduziu a accuracy ajustada para ~88%, sugerindo que a literatura atual superestima a maturidade tecnol√≥gica dos modelos \(Figura 6\)\.":
    r"Meta-analysis of 129 studies indicated a global pooled accuracy of 90.66% [95% CI: 89.8‚Äì91.4%]. The PLS-DA algorithm obtained the best mean performance (92.95%), followed by Random Forest (91.33%). However, Egger's test detected severe publication bias ($z = 40.02, p < 0.001$). Correction by trim-and-fill method (imputation of 42 missing theoretical studies) reduced the adjusted accuracy to ~88%, suggesting that current literature overestimates models' technological maturity (Figure 6).",
    
    # Se√ß√£o 3.5 - Figura 6
    r"\*\*Figure 6\.\*\* Meta-analysis of accuracies por algoritmo de Machine Learning\.":
    r"**Figure 6.** Meta-analysis of accuracies by Machine Learning algorithm.",
    
    r"\*Note: PLS-DA e Random Forest present the highest consolidated accuracies, while SVM demonstrates greater robustness \(lower variance across studies\)\. The heterogeneity moderada \(\*\$I\^2 = 58\\%\$\) indicates substantial methodological variability across studies\. Confidence intervals represent random effects estimates \(REML model\)\. \$k = 129\$ estudos\.":
    r"*Note: PLS-DA and Random Forest present the highest consolidated accuracies, while SVM demonstrates greater robustness (lower variance across studies). Moderate heterogeneity (*$I^2 = 58\\%$) indicates substantial methodological variability across studies. Confidence intervals represent random effects estimates (REML model). $k = 129$ studies.",
    
    # Se√ß√£o 3.5 - FAIR
    r"Finally, a governan√ßa de dados avaliada pelos FAIR principles atingiu um score m√©dio cr√≠tico de 34,2/100\. A dimens√£o Accessible foi a mais deficit√°ria, com apenas 10,1% dos estudos depositando dados em reposit√≥rios p√∫blicos\. Temporal analysis n√£o indicou melhorias significativas \(\$\\rho = 0,235, p = 0,379\$\), evidencesndo a estagna√ß√£o de uma cultura de \"caixa-preta\" que impede a reproducibility e a valida√ß√£o independente \(Figura 7\)\.":
    r"Finally, data governance evaluated by FAIR principles reached a critical mean score of 34.2/100. The Accessible dimension was the most deficient, with only 10.1% of studies depositing data in public repositories. Temporal analysis did not indicate significant improvements ($\\rho = 0.235, p = 0.379$), evidencing the stagnation of a \"black-box\" culture that prevents reproducibility and independent validation (Figure 7).",
    
    # Se√ß√£o 3.5 - Figura 7
    r"\*\*Figure 7\.\*\* FAIR principles compliance de governan√ßa de dados\. \(A\) Score radar por dimens√£o FAIR e \(B\) Indicatores individuais de conformidade\.":
    r"**Figure 7.** FAIR principles compliance for data governance. (A) Radar score by FAIR dimension and (B) Individual compliance indicators.",
    
    # Se√ß√£o 3.5.4 - S√≠ntese inferencial (v√°rios par√°grafos)
    r"A s√≠ntese inferencial do corpus delineia quatro fraturas estruturais que comprometem a transi√ß√£o dos atuais modelos preditivos para uma infraestrutura de Digital Terroir audit√°vel\. A primeira fratura constitutes uma ilus√£o de robustez derivada da spatial validation deficiente\.":
    r"The inferential synthesis of the corpus delineates four structural fractures that compromise the transition from current predictive models to an auditable Digital Terroir infrastructure. The first fracture constitutes a robustness illusion derived from deficient spatial validation.",
    
    r"A omiss√£o do geographically independent partitioning em 77% dos estudos precipita uma performance degradation 110% superior em testes externos, com queda m√©dia de accuracy de 11,82% versus 5,62% em modelos validados espacialmente \(U=2900, p<0,001, d=0,948\)\. Essa falha metodol√≥gica, impulsionada pela spatial autocorrelation residual, impede que os sistemas funcionem como \"G√™meos Digitais Adaptativos\", pois ao superajustarem-se a contextos locais, tornam-se obsoletos diante da climate variability real e falham na auditoria de ecosystem services em territorys an√°logos \[@Kuhn2013; @Wadoux2021\]\.":
    r"The omission of geographically independent partitioning in 77% of studies precipitates a 110% higher performance degradation in external tests, with mean accuracy drop of 11.82% versus 5.62% in spatially validated models (U=2900, p<0.001, d=0.948). This methodological failure, driven by residual spatial autocorrelation, prevents systems from functioning as \"Adaptive Digital Twins\", since by overfitting to local contexts, they become obsolete facing real climate variability and fail in ecosystem services auditing in analogous territories [@Kuhn2013; @Wadoux2021].",
    
    r"Simultaneamente, a auditabilidade regulat√≥ria √© minada pela marginaliza√ß√£o da explicabilidade\. A predomin√¢ncia de arquiteturas opacas em 86,5% das investiga√ß√µes contraria diretrizes para decis√µes de alto risco \[@Rudin2019\], sustentando-se na falsa premissa de um trade-off de desempenho\. A evid√™ncia estat√≠stica refuta essa narrativa, demonstrando que a diferen√ßa de accuracy entre modelos \"caixa-preta\" e modelos XAI √© estatisticamente n√£o significativa \(\$p = 0,218\$\), com o algoritmo XGBoost emergindo como solu√ß√£o √≥tima \(score de Pareto \$= 0,650\$\) ao equilibrar precis√£o e transpar√™ncia\. A insist√™ncia na opacidade inviabiliza a defesa jur√≠dica da certifica√ß√£o, uma vez que √≥rg√£os reguladores demandsm traceability causal entre marcadores qu√≠micos e environmental variables, e n√£o apenas correla√ß√µes latentes intraduz√≠veis\.":
    r"Simultaneously, regulatory auditability is undermined by explainability marginalization. The predominance of opaque architectures in 86.5% of investigations contradicts guidelines for high-risk decisions [@Rudin2019], sustaining itself on the false premise of a performance trade-off. Statistical evidence refutes this narrative, demonstrating that the accuracy difference between \"black-box\" models and XAI models is statistically non-significant ($p = 0.218$), with the XGBoost algorithm emerging as optimal solution (Pareto score $= 0.650$) by balancing precision and transparency. Insistence on opacity makes certification legal defense unfeasible, since regulatory bodies demand causal traceability between chemical markers and environmental variables, not just untranslatable latent correlations.",
}

def aplicar_traducoes(arquivo_entrada, arquivo_saida):
    """Aplica todas as tradu√ß√µes no arquivo"""
    with open(arquivo_entrada, 'r', encoding='utf-8') as f:
        conteudo = f.read()
    
    conteudo_original = conteudo
    traducoes_aplicadas = 0
    
    for padrao_pt, texto_en in traducoes.items():
        if re.search(padrao_pt, conteudo):
            conteudo = re.sub(padrao_pt, texto_en, conteudo)
            traducoes_aplicadas += 1
            print(f"‚úì Tradu√ß√£o aplicada: {padrao_pt[:80]}...")
    
    if conteudo != conteudo_original:
        with open(arquivo_saida, 'w', encoding='utf-8') as f:
            f.write(conteudo)
        print(f"\n‚úÖ {traducoes_aplicadas} tradu√ß√µes aplicadas com sucesso!")
        print(f"üìÑ Arquivo salvo: {arquivo_saida}")
        return True
    else:
        print("‚ö†Ô∏è Nenhuma tradu√ß√£o foi aplicada (padr√µes n√£o encontrados)")
        return False

if __name__ == "__main__":
    arquivo_entrada = r"c:\Users\vidal\OneDrive\Documentos\13 - CLONEGIT\revisaoescopo\1-MANUSCRITO\revisao_escopo_en.md"
    arquivo_saida = arquivo_entrada  # Sobrescrever o mesmo arquivo
    
    print("="*70)
    print("FINALIZADOR DE TRADU√á√ÉO - MANUSCRITO EN")
    print("="*70)
    print(f"\nProcessando: {arquivo_entrada}\n")
    
    sucesso = aplicar_traducoes(arquivo_entrada, arquivo_saida)
    
    if sucesso:
        print("\n" + "="*70)
        print("üéØ TRADU√á√ÉO 100% CONCLU√çDA!")
        print("="*70)
    else:
        print("\n" + "="*70)
        print("‚ÑπÔ∏è Verifique manualmente os trechos restantes")
        print("="*70)
